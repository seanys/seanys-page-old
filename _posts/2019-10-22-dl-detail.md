---
layout: post
title: "机器学习基础及记录（基础技术）"
subtitle: 'Machine Learning Part 1'
author: "sean"
header-img: "img/post-bg-ai.jpeg"
tags:
  - 算法
  - 机器学习
  - 数据挖掘

---



> 该内容仅为个人学习记录和理解，不是教程，具体内容可以参考 https://www.zybuluo.com/hanbingtao/note/433855 有全部教程



## 感知器

**输入值**：$x$ 是多个输入值

**权重**：$w$ 是一个向量

**偏置项**：$b$

**计算结果**：$w·x+b$ 是初始的计算结果，但是不能直接用

**激活函数**：比如$relu$，其实就是对计算结果的调整，拟合是或否

**本质**：线性一个线性平面对空间中的点进行划分

**过程**：根据数据与结果的差异，对w与b进行调整，获得最终结果

**调整一**：$\Delta w_i=\eta (t-y)x_i$ 对每一个权重的值进行调整

**调整一**：$\Delta b=\eta (t-y)$ 直接计算实际值-计算值*学习速度

源码：https://github.com/seanys/Algorithm-Learn/blob/master/Deep%20Learning/activators.py 参考教程，后续可能会修改

## 线性单元

**差异**：输出值是具体值，适用于线性回归





参考资料：https://www.zybuluo.com/hanbingtao/note/448086

## 神经网络



参考资料：https://www.zybuluo.com/hanbingtao/note/476663

## GAN

https://zhuanlan.zhihu.com/p/24767059



## Hopfield

![img](https://upload.wikimedia.org/wikipedia/commons/9/95/Hopfield-net.png)

Hopfield网络的单元是二元的（binary），即这些单元只能接受两个不同的值，并且值取决于输入的大小是否达到阈值。Hopfield网络通常接受值为-1或1，也可以是0或者1。输入是由[sigmoid函数](https://zh.wikipedia.org/wiki/Sigmoid函数)处理得到的。 sigmoid函数定义为：

$$S(t) = \frac{1}{1 + e^{-t}}$$

用于将输入化简为两个极值。

每一对Hopfiled网络的单元*i*和*j*间都有一对以一定权重（weight）的连接$ w_{ij} $。因此，Hopfiled网络可被描述为一个完整的无向图$ G = <V, f> $，其中$V$是人工神经元集合。 

Hopfiled网络的连接有以下特征：

- $$w_{ii}=0, \forall i$$
- $$w_{ij} = w_{ji}, \forall i,j$$（连接权重是对称的）

权重对称的要求是一个重要特征，因为它保证了能量方程（称向函数某一点收敛的过程为势能转化为能量）在神经元激活时单调递减，而不对称的权重可能导致周期性的递增或者噪声。然而，Hopfiled网络也证明噪声过程会被局限在很小的范围，并且并不影响网络的最终性能

Hopfield最早提出的网络是二值神经网络，各神经元的激励函数为阶跃函数或双极值函数,神经元的输入、输出只取{0，1}或者{ -1，1}，所以也称为**离散型Hopfield神经网络DHNN**（Discrete Hopfiled Neural Network）。在DHNN中，所采用的神经元是二值神经元；因此，所输出的离散值1和0或者1和-1分别表示神经元处于激活状态和抑制状态。

离散Hopfield神经网络DHNN是一个**单层**网络，有n个神经元节点，每个神经元的输出均接到其它神经元的输入。各节点**没有自反馈**。每个节点都可处于一种可能的状态（1或－1），即当该神经元所受的刺激超过其阀值时，神经元就处于一种状态（比如1），否则神经元就始终处于另一状态（比如－1）。

备注：没看懂

参考资料：https://www.ofweek.com/ai/2018-05/ART-201717-11001-30228892.html

## GRU



## STLM

