---
layout: post
title: "计算效率提高策略"
subtitle: '采用Python的情况下如何提高计算效率'
author: "sean"
header-img: "img/post-bg-ai.jpeg"
tags:
  - Machine Learnings

---

# 计算效率提高策略

今年做的二维排样和拼车

在Python的程序中，我们需要进行重复迭代，由于Python的for循环计算很慢，同时数据量过大，会造成计算时间非常长，以我们当前的研究内容为例，解释如何进行速度优化

## 策略一-矩阵计算

在部分计算中，存在非常多的循环计算，就会出现大量的for循环，这种情况下，需要想办法将部分运算改为numpy计算，由于底层采用了C++编写，其效率会更高。

```python
import numpy as np
arr1 = np.array([1,2,3])
arr2 = np.array([2,3,4])
print(arr1*arr2.T)
```

## 策略二-字典检索

相对而言，dictionary的检索速度比list的速度会更快，我们的数据存储存在origin vertex和destination vertex，共同存储在OD中，这就需要存储为二维数组。由于：

1. 并非全部的OD都存在合适的订单，如果存储二维数组会出现大量冗余数据
2. List的读取速度和检索速度都不及Dictionary，后者的检索速度为O(1)，在检索规模比较大的时候，list判断是否存在速度非常慢

所以，优先采用字典进行处理

```python
# 设计唯一Key值
dic = {}
key = ""
dic[key] = "detail"
# 查询是否存在
if key in dic:
  print("exist")
# 遍历全部Key
for key in dic.keys():
  print(key)
```

## 策略三-分析计算内容

在大规模的数据计算中，会出现部分函数的执行时间过长，建议通过Cprofile进行时间分析，比如以下分析可以看到，obtainLamS所花费的时间是最长的，同时还有obtainP，然后我们就可以通过数据结构优化、算法优化等策略，优化该函数，降低执行次数。

```Python
  34372393 function calls (34191034 primitive calls) in 123.443 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)

      236    8.009    0.034    8.010    0.034 prediction.py:377(obtainLamSDNA)
      236   74.598    0.316   74.629    0.316 prediction.py:390(obtainLamS)
      236   20.741    0.088   21.518    0.091 prediction.py:408(obtainP)
        1    0.005    0.005    0.006    0.006 prediction.py:426(getNumberLamSN)
     1416    0.007    0.000    9.689    0.007 prediction.py:433(getBias)
     1416    7.893    0.006    9.216    0.007 prediction.py:435(<listcomp>)
 16865032    1.322    0.000    1.322    0.000 {built-in method builtins.abs}
```

## 策略四-多核计算





## 策略五-采用Cpython







