---
layout: post
title: "训练结果记录"
subtitle: '算法和实验结果的记录'
author: "sean"
header-img: "img/post-bg-ai.jpeg"
tags:
  - Bin packing
  - Machine Learnings

---

## 11.27 训练记录

### 数据来源

参考jakjob选择了两个形状，不规则三角形和缺了一个口的长方形，随机生成对应的形状

#### 缺口长方形

```python
						width=random.randint(100,500)
            height=random.randint(100,500)
            poly=[[500,500],[500+width,500],[500+width,500+height],[500,500+height]] #生成初始形状
            extend_poly=poly+poly
            # 生成随机位置和获得点
            choose_index=random.randint(3,6)
            pt=extend_poly[choose_index]
            pre_pt=extend_poly[choose_index-1]
            next_pt=extend_poly[choose_index+1]
            # 获得中间点
            lambda1=random.uniform(0.2,0.8)
            lambda2=random.uniform(0.2,0.8)
            mid_pre=self.getMid(pre_pt,pt,lambda1)
            mid_next=self.getMid(pt,next_pt,lambda2)
            # 获得新的形状
            for i in range(3,7):
                if i==choose_index:
                    new_poly.append(mid_pre)
                    if mid_pre[0]==extend_poly[choose_index-1][0]:
                        new_poly.append([mid_next[0],mid_pre[1]])
                    else:
                        new_poly.append([mid_pre[0],mid_next[1]])
                    new_poly.append(mid_next)
                else:
                    new_poly.append(extend_poly[i])
            return new_poly
```

#### 三角形

```python
						pt1=[250,250]
            pt2=[]
            pt3=[]
            if random.randint(0,1)==0:
                pt2=[250+random.randint(100,250),250]
                pt3=[250+random.randint(25,pt2[0]+20),250+random.randint(50,250)]
            else:
                pt2=[250+random.randint(25,250),250-random.randint(50,250)]
                pt3=[250+random.randint(pt2[0]-270,250),250]
            return [pt1,pt2,pt3]
```

#### 组合模式

一般情况下是在空缺位置、底部、左侧和右侧、上侧和下侧平的地方

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9d1t0iuelj30u00xfjtf.jpg" alt="image-20191128001024652" style="zoom:33%;" />

### 训练结果

#### 训练网络

数据标准化：y是centroid的方向向量进行标准化(0-1)，x对centroid outside的数据进行了清理，暂时不考虑

损失函数：交差熵损失函数

#### 排样结果

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9d37jjgm0j30sc110aap.jpg" alt="image-20191128005857304" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9d37ts8x3j30r00voab8.jpg" alt="image-20191128005913649" style="zoom:33%;" />

#### 统计结果

4000个样本训练，2000个样本检验，1000 epoch，batch size=256，简单的反向传播网络

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9d34isq8bj30zk0qo0uc.jpg" alt="accu_pos_pos_1000_layer_256_128_32_batch_256" style="zoom:50%;" />

1000个样本训练，剩下5000个样本检验，100 epoch，batch size=256，简单的反向传播网络

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9d34ocyhhj30zk0qojtp.jpg" alt="acc_sample_1000_pos_pos_epoch_100_layer_256_128_32_batch_256" style="zoom:50%;" />

### 结果分析

1. **类似于线性回归**：向量表示了形状的特征，一个形状放在另一个形状的上下左右的一个合理的位置，其实就是一个多维的分类问题，根据长宽高还有缺口的宽度，我们可以预测形状应该摆放的位置
2. **可能存在数据类似的问题**：由于数据可能是存在枚举的情况，也就是相当于拟合了train数据后，拟合vali数据就基本一样了。但是采用了1000样本后，其训练结果还是类似的，至少有(250x250x4)x(250x250x2)个组合情况，降低精度也有(25x25x4)x(25x25x2)=2500*1250个组合，不可能枚举的，只是学习了组合的模式
3. **验证了样片组合的可能性**：人脑对两个样片的组合思路和计算机的组合是类似，根据边界的情况可以直接获得一个大致的模型
4. **需要进行两个样片的优化**：排样的最后结果只是大致预测出的方向，没有预测出精准的位置，所以需要在这个方向上寻找一个合适的位置，比如边界点之类的
5. **学习给出的样片组合**：如果给出了几个样片，Ax4, Bx5, Dx10这样子，然后8个样片的组合有非常多个，可以采用其中的部分模型进行学习，然后给出8个样片可以直接知道其大致的组合情况
6. **学习未见过的模型**：基本类似，可以对部分组合情况进行学习（大规模的没有比较好的结果），然后通过输入几个样片，可以直接给出最终的基本布局，该布局可以通过overlap remove的一些算法进行初始处理，然后通过local search的一些方法进行优化

## 11.26 训练记录

### 模型相关

#### Batch选择

1. Batch_Size 太小，算法在 200 epoches 内不收敛。
2. 随着 Batch_Size 增大，处理相同数据量的速度越快。
3. 随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。
4. 由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到**时间上**的最优。
5. 由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛**精度上**的最优。

**可不可以选择一个适中的 Batch_Size 值呢？**如果数据集足够充分，那么用一半（甚至少得多）的数据训练算出来的梯度与用全部数据训练出来的梯度是几乎一样的。

**在合理范围内，增大 Batch_Size 有何好处？**

- 内存利用率提高了，大矩阵乘法的并行化效率提高。
- 跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。
- 在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。

**盲目增大 Batch_Size 有何坏处？**

- 内存利用率提高了，但是内存容量可能撑不住了。
- 跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。
- Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。

#### 隐藏层与隐藏单元

1、隐藏单元的数量不应该超过输入层中单元的两倍（M. J. A. Berry and G. S. Linoff, Data Mining Techniques: For Marketing, Sales, and Customer Support, New York: John Wiley & Sons, 1997.）

2、隐藏单元的大小应该介于输入单元和输出单元之间（A. Blum, Neural Networks in C++, New York: Wiley, 1992.）

3、神经元的数量应捕获输入数据集方差的70~90%（Z. Boger and H. Guterman, "Knowledge extraction from artificial neural network models," in Systems, Man, and Cybernetics, 1997. Computational Cybernetics and Simulation., 1997 IEEE International Conference, Orlando, FL, 1997.）

### 18:00 重建结果分析

#### 重建结果

**预期结果**

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9bnzb8wzbj30u00vjdgs.jpg" alt="messigray" style="zoom:30%;" />

**实际结果**

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9bo0l6a2mj30u00u03z2.jpg" alt="messigray" style="zoom:33%;" />

#### 结果分析

1. 预期的结果和实际的结果差异性非常大
2. 类似的数据组合的预测结果类似（类似形状输入）
3. 虽然统一了数据集大小，但是输入形状的差异性非常大
4. 输入0-255和256-511的值都是绑定的，没有扰动

#### 优化方案

1. 所有的输入内容可以采用随机形状，但是相同和类似尺寸，有凹有凸
2. 生成形状-形状组合-训练集合-比较小一点的规模数据就可以了-尽快生成和测试
3. 今晚搞定！！！加油！！！！

### 15:00 数据刷新训练

#### 数据刷新后训练

256-128-32-2网络重新训练

![1000-sigmoid-11-26](https://tva1.sinaimg.cn/large/006y8mN6gy1g9bnxg00guj31e30u0jvd.jpg)

去除99999数据（采纳）

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9bnk8cadej314p0u0n1x.jpg" alt="300-sigmoid-double-11-26" style="zoom:47%;" />

Vector部分取值为负全部变正（不采用）

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9bnjb329mj31by0u0tcp.jpg" alt="500-clean-999-11-26" style="zoom:40%;" />

#### 训练分析

没什么好说的，数据标准化没问题，网络来看也是问题不大，整体就是拟合一个线性回归的方程，但是数据训练本身有问题

## 11.25训练记录

### 23:30训练结果

#### 结果分析



<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9apupo9rsj319a0u00x1.jpg" alt="500-11-25-acc" style="zoom:33%;" />

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9apunj2pzj318u0u0jw1.jpg" alt="500-11-25" style="zoom:33%;" />

### 22:30训练结果

#### 优化思路

主要可以通过以下几个方案优化，优先尝试模型预测情况，然后优化网络，如果还是不行，再去思考怎么生成训练集合，周二搞定，加油你可以的！

- [ ] 保存模型并直接测试结果情况
- [ ] 优化网络结构和损失函数
- [ ] 训练集的负值的去除处理

- [ ] 重新建立数据集，随机生成合理数据并进行排样

#### 数据集来源

EURO的部分数据组合结果，约10000条数据

#### 结果分析

1. 全部采用sigmoid，三层
2. 数据进行归一化处理
3. 训练结果大概在500左右达到最优，后续过拟合
4. 整体的验证集的准确率比较低

<img src="/Users/sean/Documents/Projects/Algorithm Learn/Packing Algorithm/picture/3000-11-25.png" alt="3000-11-25" style="zoom:28%;" />

<img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g9apeyimdmj318z0u0q6m.jpg" alt="3000-11-25-acc" style="zoom:40%;" />

## 11.10训练记录

### 数据集来源

随机生成数据，一个缺角的长方形和比较小的长方形和正方形，可以直接预测最合适的位置

### 模型分析

本质上来说，就是一个线性函数，比较简单就能够拟合出结果

### 训练结果

![B94F1EE1-9439-43F1-B4CB-FDB8A11E065A_1_102_o](/Users/sean/Pictures/照片图库.photoslibrary/resources/derivatives/B/B94F1EE1-9439-43F1-B4CB-FDB8A11E065A_1_102_o.jpeg)

![F5577822-0378-4647-8D4B-72513407A813_1_105_c](https://tva1.sinaimg.cn/large/006y8mN6gy1g9aptgcpwbj30v50jggq1.jpg)